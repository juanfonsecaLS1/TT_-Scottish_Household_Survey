---
title: "Transport and Travel - Scottish Household Survey"
output: github_document
bibliography: scotrefs.bib 
csl: ieee.csl
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      message=FALSE,
                      warning=FALSE)
```

The goal of this repository is to analyse the results of the Scottish Household Survey from 2014 to 2019 @SHS14,@SHS15,@SHS16,@SHS17,@SHS18,@SHS19 to estimate the overall mode splits and temporal distribution of trips made by bicycle. Some details on the weighting methodology of the survey can be found [here](https://www.gov.scot/publications/scottish-household-survey-2021-methodology-fieldwork-outcomes/pages/7/)

All the zip files have been obtained from the [UK data service](https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=8775)

First of all, a copy of the original files can be obtained with the code below. This code is to be run just once.

```{r}
#| eval = FALSE
dir.create("raw_data")
system("gh release download 1 --dir raw_data")
```

We can list the files with the following code:

```{r cars}
zip_files = list.files("raw_data/","\\.zip$",full.names = T)
zip_files
```

All the zipped files are extracted with the following code:

```{r}
#| eval = FALSE

for (file in zip_files){  
  unzip(file,exdir = "raw_data")
  }
```

Once the files have been unzipped, the `*.sav` files containing the journey diaries are listed as follows:

```{r}
SPSS_files = list.files(pattern = "journey.*\\.sav$",
                        recursive = T,full.names = T)
SPSS_files
```

All files are imported using the `haven` library with this code:

```{r}
library(haven)
library(tidyverse)
library(kableExtra)

data = do.call(bind_rows,lapply(SPSS_files,read_sav))

data |> head()
```

We are only interested in trips made by bicycle. According to the data dictionaries, the corresponding code is `4`.

```{r}
data_bicycle = data |> filter(mainmode == 4)
data_bicycle |> head()
```

We can calculate the purpose split for the bicycle trips using the weight variables as follows:

```{r}
summary_purpose = data_bicycle |>
  summarise(Trips = sum(trav_wt),
            .by = c(purpose_old)) |> 
  mutate(Split = Trips/sum(Trips))
summary_purpose
```

The `summary_purpose` object has coded variables which are stored as labelled vectors. The following code allows us to extract the labels from the `purpose_old` column.

```{r}
summary_purpose = summary_purpose |> 
  mutate(purpose_old = haven::as_factor(purpose_old))
summary_purpose
```

```{r mode_split}
#| echo = FALSE
summary_purpose |>
  data.frame() |> 
  mutate(purpose_old = fct_reorder(purpose_old, Split)) |> 
  ggplot(aes(x = purpose_old, y = Split))+
  scale_y_continuous(labels = scales::percent)+
  geom_col()+
  coord_flip()
```

Similarly, the split by year can be calculated with the following code:

```{r}
summary_purpose_year = data_bicycle |>
  summarise(Trips = sum(trav_wt),
            .by = c(purpose_old,dyear)) |> 
  mutate(Split = Trips/sum(Trips),.by = c(dyear))
```

The years are also a coded variable.

```{r}
summary_purpose_year = summary_purpose_year |>
  mutate(purpose_old = haven::as_factor(purpose_old),
         dyear = haven::as_factor(dyear))
summary_purpose_year
```

We can see how the splits for the five most common purposes have changed from year to year. For this purpose, we extract the top 5 purposes from the previous analysis.

```{r}
top_5_purposes = summary_purpose |> slice_max(Split,n = 5) |> pull(purpose_old)
top_5_purposes
```

We need to remove the `dataset/script` or extract the numerical part of the dyear column for plotting.

```{r}
summary_purpose_year |> 
  filter(purpose_old %in% top_5_purposes) |> 
  mutate(Year = as.integer(str_extract(dyear,"\\d*")), 
         purpose_old = fct_reorder(purpose_old, Split)) |> 
  ggplot(aes(x = Year, y = Split, col = purpose_old)) + 
  geom_line(linewidth = 1)+
  scale_color_viridis_d()+
  scale_y_continuous(labels = scales::percent)

```

The high variation of the splits might be linked to the different samples for each year's survey.

## Temporal Distribution of trips

Using the start time when the recorded trips (`journeystart_hh`), we can build an hourly profile of the trips.

```{r}
hourly_summary = data_bicycle |> 
  summarise(Trips = sum(trav_wt),
            .by = c(journeystart_hh))
hourly_summary
```

The following code is used to plot the hourly trips profile.

```{r}
hourly_summary |>
  ggplot(aes(x=journeystart_hh,y = Trips))+
    geom_line(linewidth = 0.7,col = "blue")+
  geom_hline(yintercept = 0)+
  theme_minimal()
```

We can also produce the same analysis by trip purpose.

```{r}
hourly_summary_purpose = data_bicycle |> 
  summarise(Trips = sum(trav_wt),
            .by = c(journeystart_hh,purpose_old)) |> 
  mutate(purpose_old = haven::as_factor(purpose_old))
  
hourly_summary_purpose
```

As shown in the plot below, the *commuting* and *education* trips have two clear peaks; for all other purposes the temporal patterns are less clear.

```{r}
hourly_summary_purpose |>
  filter(purpose_old %in% top_5_purposes) |>
  mutate(purpose_old = fct_reorder(purpose_old, Trips)) |> 
  ggplot(aes(x=journeystart_hh,y = Trips, col = purpose_old))+
  geom_line(linewidth = 0.7)+
  geom_hline(yintercept = 0)+
  theme_minimal()+
  scale_colour_viridis_d()
    
```

## Trip Length Distribution

The following section includes a brief analysis of the trip length distribution. For this analysis, the following distance bands are defined (in km)

```{r}
tld_bands = c(0,5,10,15,25,50,100,500,1000,2500)
```

### By mode

```{r}
TLD_mode = data |> 
  mutate(dist_band = cut(roadnet_kms,
                         breaks = tld_bands,
                         include.lowest = T),
         ) |>
  summarise(Trips = sum(trav_wt,na.rm = T),
            .by = c(mainmode,dist_band)) |> 
  mutate(perc = Trips/sum(Trips),
         .by = c(mainmode))
```

```{r}
TLD_mode |> 
  drop_na(dist_band) |> 
  ggplot(aes(x=dist_band,y=perc,fill=haven::as_factor(mainmode)))+
  geom_col()+
  facet_wrap(haven::as_factor(mainmode)~.)+
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 90))
```

### By purpose

The following exercise uses the `purpose_old` categories. A finer analysis is possible if the `purpose_new` and `purpose_new2`

```{r}
TLD_purpose = data |>
  mutate(dist_band = cut(roadnet_kms,
                         breaks = tld_bands,
                         include.lowest = T),
         ) |>
  drop_na(dist_band) |> 
  summarise(Trips = sum(trav_wt,na.rm = T),
            .by = c(purpose_old,dist_band)) |> 
  mutate(perc_band = Trips/sum(Trips),
         .by = c(purpose_old)) |> 
  mutate(perc_purp = Trips/sum(Trips),
         .by = c(dist_band))

```

```{r}
TLD_purpose |> 
  ggplot(aes(x=dist_band,y=perc_purp,fill=haven::as_factor(purpose_old)))+
  geom_col(position = "fill")+
  scale_y_continuous(labels = scales::percent_format())+
  theme(legend.position = "bottom",
        axis.text.x = element_text(angle = 90))
```

```{r}
TLD_purpose |> 
  ggplot(aes(x=dist_band,y=perc_purp,fill=haven::as_factor(purpose_old)))+
  geom_col()+
  scale_y_continuous(labels = scales::percent_format())+
  facet_wrap(haven::as_factor(purpose_old)~.)+
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 90))
```

### By mode and purpose

```{r}
TLD_mode_purp = data |> 
  mutate(dist_band = cut(roadnet_kms,
                         breaks = tld_bands,
                         include.lowest = T),
         ) |>
  summarise(Trips = sum(trav_wt,na.rm = T),
            .by = c(mainmode,purpose_old,dist_band)) |> 
  mutate(perc = Trips/sum(Trips),
         .by = c(mainmode,purpose_old))

```

```{r}
TLD_mode_purp |> 
  drop_na(dist_band, mainmode) |> 
  filter(mainmode<9) |> 
  ggplot(aes(x=dist_band,y=perc,fill=haven::as_factor(purpose_old)))+
  geom_col()+
  facet_wrap(haven::as_factor(mainmode)~.)+
  theme(legend.position = "bottom",
        axis.text.x = element_text(angle = 90))
```

## Annualisation factors calculation

In order to estimate the trip frequency by purpose, . The following code loads the data into the environment which contains the stage tables from the survey.

```{r}
#| warning=FALSE
SPSS_files_stage = list.files(pattern = "stage.*\\.sav$",
                        recursive = T,full.names = T)

data.stage = do.call(bind_rows,lapply(SPSS_files_stage,read_sav))
```

### Bike baseline

As in the previous analysis, we are interested only in the bicycle trips (`mode` = `4`). Although bike might not be the main mode for all the trip, all bike stages are considered for this analysis. Subsequently, we select the columns of interest

```{r}
bike_stages <- data.stage |> 
  filter(sum(mode == 4)>0,.by = c(UNIQIDNEW,dyear,trav_wt,travday)) |> 
  select(mode,UNIQIDNEW,dyear,IND_WT,trav_wt,purpose_new,travday)
```

Firstly, we explore the overall trip frequency splits by day of the week

```{r}
bike_stages |> 
  filter(mode ==4) |> 
  summarise(Total = sum(trav_wt,na.rm = T),
            .by = c(dyear,travday)) |> 
  mutate(Perc = Total/sum(Total),
         .by = c(dyear)) |> 
  select(-Total) |> 
  ggplot(aes(x=haven::as_factor(dyear), y = Perc, fill = haven::as_factor(travday)))+
  scale_y_continuous(
    # limits = c(0,0.3),
    labels = scales::percent)+
  geom_col()+
  scale_fill_viridis_d()+
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 30,vjust = 1,hjust = 1))+
  labs(x= "year/dataset",y=NULL,fill = "Day",title = "Portion of trips by day of travel")
```

```{r}
bike_stages |> 
  filter(mode ==4) |> 
  summarise(Total = sum(trav_wt,na.rm = T),
            .by = c(dyear,travday)) |> 
  mutate(Perc = Total/sum(Total),
         .by = c(dyear)) |> 
  select(-Total) |> 
  ggplot(aes(x="Overall", y = Perc/sum(Perc), fill = haven::as_factor(travday)))+
  scale_y_continuous(
    # limits = c(0,0.3),
    labels = scales::percent)+
  geom_col()+
  scale_fill_viridis_d()+
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 30,vjust = 1,hjust = 1),legend.position = "bottom")+
  labs(x= NULL,
       y=NULL,fill = "Day",title = "Portion of trips by day of travel")+
  coord_flip()
```

Since travel patters and frequency would vary among trip purposes, we need to produce a more disaggregated analysis. Thus, we first define groups of trip purposes from the `new_purpose` column. The following code identifies the different trip purposes that people logged in their trip diaries of the survey when using the bike.

```{r}
SHS_purposes_bike <- bike_stages |>
  select(purpose_new) |>
  unique() |> 
  mutate(p.label = as_factor(purpose_new))
```

, A correspondence between trip purposes for the NPT project has been defined as follows:

```{r}
NPT_purposes_equiv <- tribble(
  ~ purpose_new,  ~ NPT_purpose,
  3, 'Commute',
  103, 'Commute',
  4, 'Shopping',
  104, 'Shopping',
  15, 'Other',
  29, 'Other',
  129, 'Other',
  1, 'Other',
  115, 'Other',
  34, 'Leisure',
  6, 'Visiting',
  19, 'Other',
  24, 'Other',
  106, 'Visiting',
  5, 'Visiting',
  105, 'Visiting',
  12, 'Leisure',
  112, 'Leisure',
  11, 'School',
  111, 'School',
  30, 'Other',
  130, 'Other',
  23, 'Other',
  123, 'Other',
  7, 'School',
  107, 'School',
  2, 'Other',
  102, 'Other',
  36, 'Other',
  31, 'Other',
  131, 'Other',
  119, 'Other',
  35, 'Other',
  26, 'Leisure',
  126, 'Leisure',
  25, 'Leisure',
  125, 'Leisure',
  17, 'Other',
  22, 'Other',
  122, 'Other',
  135, 'Other',
  124, 'Other',
  33, 'Other',
  136, 'Other',
  117, 'Other',
  226, 'Leisure',
  18, 'Other',
  118, 'Other',
  13, 'Other',
  113, 'Other',
  133, 'Other',
  114, 'Leisure',
  134, 'Leisure'
)
```

The following table shows how the `new_purpose` values have been grouped into 6 wider categories:

```{r}
tbl_purposes <- SHS_purposes_bike |>
  left_join(NPT_purposes_equiv,by = "purpose_new") |>
  arrange(NPT_purpose) 

kable(tbl_purposes |>
                       select(-NPT_purpose)) |>
  pack_rows(index = table(tbl_purposes$NPT_purpose)) |> 
  kable_classic(full_width = F) |>
  as_image(width = 10,file = "README_files/figure-gfm/purpose_table.png")
```

Based on this purposes, we can produce a plot for proportion of trips by day of travel for each dataset

```{r}
bike_stages |> 
  filter(mode ==4) |>
left_join(NPT_purposes_equiv,by = "purpose_new") |>    
  summarise(Total = sum(trav_wt,na.rm = T),
            .by = c(dyear,travday,NPT_purpose)) |> 
  mutate(Perc = Total/sum(Total),
         .by = c(dyear,NPT_purpose)) |> 
  select(-Total) |> 
  ggplot(aes(x=haven::as_factor(dyear), y = Perc, fill = haven::as_factor(travday)))+
  scale_y_continuous(
    # limits = c(0,0.3),
    labels = scales::percent)+
  geom_col()+
  facet_wrap(NPT_purpose~.)+
  scale_fill_viridis_d()+
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 30,vjust = 1,hjust = 1))+
  labs(x= "year/dataset",y=NULL,fill = "Day",title = "Portion of trips by day of travel")

```

Similarly, an the overall day of travel and purpose splits can be visualised with the following code

```{r}
bike_stages |> 
  filter(mode ==4)|> 
left_join(NPT_purposes_equiv,by = "purpose_new") |>    
  summarise(Total = sum(trav_wt,na.rm = T),
            .by = c(travday,NPT_purpose)) |> 
  mutate(Perc = Total/sum(Total),
         .by = c(NPT_purpose)) |> 
  select(-Total) |> 
  ggplot(aes(x = NPT_purpose, y = Perc, groups = NPT_purpose, fill = haven::as_factor(travday)))+
  scale_y_continuous(
    # limits = c(0,0.3),
    labels = scales::percent)+
  geom_col()+
  # facet_wrap(NPT_purpose~.)+
  scale_fill_viridis_d()+
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 30,vjust = 1,hjust = 1))+
  labs(x= "year/dataset",y=NULL,fill = "Day",title = "Portion of trips by day of travel")
```

```{r}
bike_stages |> 
  filter(mode ==4) |> 
left_join(NPT_purposes_equiv,by = "purpose_new") |>    
  summarise(Total = sum(trav_wt,na.rm = T),
            .by = c(travday,NPT_purpose)) |> 
  mutate(Perc = Total/sum(Total),
         .by = c(travday)) |> 
  select(-Total) |> 
  ggplot(aes(x = haven::as_factor(travday), y = Perc, fill = NPT_purpose))+
  scale_y_continuous(
    # limits = c(0,0.3),
    labels = scales::percent)+
  geom_col()+
  # facet_wrap(NPT_purpose~.)+
  scale_fill_brewer(palette = "Set2")+
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 30,vjust = 1,hjust = 1))+
  labs(x= "year/dataset",y=NULL,fill = "Day",title = "Portion of trips by day of travel made by bike")
```

In order to produce the annualisation factors, we have to estimate the trip frequency by purpose from the survey. First the number of trips by day of the week is calculated for each respondent of the survey. Then, we calculate the weighted mean all respondents using the travel diary weight (`trav_wt`). This calculations are applied by each category of the NTP purposes.

```{r}
purpose_trips_bike_BL = bike_stages |> 
  filter(mode ==4) |>
  left_join(NPT_purposes_equiv,by = "purpose_new") |> 
  summarise(N_trips = n(),
            .by = c(dyear,travday,UNIQIDNEW,NPT_purpose,trav_wt)) |> 
  summarise(N_trips = sum(N_trips*trav_wt,na.rm = T),
            .by = c(dyear,NPT_purpose,travday))

total_respondents_bike_BL = bike_stages |>
  select(dyear,UNIQIDNEW,trav_wt,travday) |> 
  unique() |> 
  summarise(N_ind = sum(trav_wt,na.rm = T),
            .by = c(dyear,travday))

N_bar_daily_BL = purpose_trips_bike_BL |> 
  left_join(total_respondents_bike_BL,
            by=join_by(dyear,travday)) |> 
  mutate(N_bar = N_trips/N_ind) |> 
  summarise(across(N_bar,mean,na.rm = T),.by = c(NPT_purpose,travday)) |> 
  arrange(NPT_purpose,travday)

N_bar_daily_BL |>
  pivot_wider(names_from = NPT_purpose,
              values_from = N_bar,
              values_fill = 0) |>
  arrange(travday)

```

In order to consider the different weights of each type of day in a year i.e., the total number of Mondays, Tuesdays, etc; days are grouped into weekdays, Saturdays and Sundays/bank holidays. Finally, assuming that every year in Scotland has 250 weekdays, 52 Saturdays and 63 Sundays/Bank holidays, we calculate the annualisation factor for each trip purpose.

```{r}
AADT_factors_bike_BL <- N_bar_daily_BL |>
  mutate(d.weight = case_when(travday < 6 ~ 50,
                              travday == 6 ~ 52,
                              travday == 7 ~ 63)) |>
  summarise(AADT_bike = weighted.mean(N_bar, w = d.weight),
            .by = NPT_purpose)

AADT_factors_bike_BL |>
  mutate(weekly_trips = AADT_bike*7)
```

***NOTE:*** The commute trip rate is normalised for all adult population i.e., employed + unemployed.

### All modes AADT

A similar analysis is undertaken for all modes to estimate the trip frequency across all modes for different purposes

```{r}
purpose_trips_all = data.stage |>
  left_join(NPT_purposes_equiv,by = "purpose_new") |> 
  mutate(NPT_purpose = if_else(is.na(NPT_purpose),"Other",NPT_purpose)) |> 
  summarise(N_trips = n(),
            .by = c(dyear,travday,UNIQIDNEW,NPT_purpose,trav_wt)) |> 
  summarise(N_trips = sum(N_trips*trav_wt,na.rm = T),
            .by = c(dyear,NPT_purpose,travday))

total_respondents_all = data.stage |>
  select(dyear,UNIQIDNEW,trav_wt,travday) |> 
  unique() |> 
  summarise(N_ind = sum(trav_wt,na.rm = T),
            .by = c(dyear,travday))

N_bar_daily_all = purpose_trips_all |> 
  left_join(total_respondents_all,
            by=join_by(dyear,travday)) |> 
  mutate(N_bar = N_trips/N_ind) |> 
  summarise(across(N_bar,mean,na.rm = T),.by = c(NPT_purpose,travday)) |> 
  arrange(NPT_purpose,travday)

N_bar_daily_all |>
  pivot_wider(names_from = NPT_purpose,
              values_from = N_bar,
              values_fill = 0) |>
  arrange(travday)
```

```{r}
AADT_factors_all <- N_bar_daily_all |>
  mutate(d.weight = case_when(travday < 6 ~ 50,
                              travday == 6 ~ 52,
                              travday == 7 ~ 63)) |>
  summarise(AADT_all = weighted.mean(N_bar, w = d.weight),
            .by = NPT_purpose)

AADT_factors_all |>
  mutate(weekly_trips = AADT_all*7)
```

***NOTE:*** The commute trip rate is normalised for all adult population i.e., employed + unemployed.

### Commute

The same approach as in the previous section is followed for the commuting trips, the only difference is that in this case only the employed population is considered.

#### Bike BL commute

```{r}
bike_stages_employed <- data.stage |>
  filter(between(randecon, 1, 3) | randecon == 9) |>
  filter(sum(mode == 4) > 0,
         .by = c(UNIQIDNEW, dyear, trav_wt, travday)) |>
  select(mode,UNIQIDNEW,dyear,IND_WT,trav_wt,purpose_new,travday)
```

```{r}
purpose_trips_bike_BL_employed = bike_stages_employed |>
  filter(mode == 4) |>
  left_join(NPT_purposes_equiv, by = "purpose_new") |>
  filter(NPT_purpose == "Commute") |>
  summarise(
    N_trips = n(),
    .by = c(dyear, travday, UNIQIDNEW, NPT_purpose, trav_wt)
  ) |>
  summarise(
    N_trips = sum(N_trips * trav_wt, na.rm = T),
    .by = c(dyear, NPT_purpose, travday)
  )

total_respondents_bike_BL_employed = bike_stages_employed |>
  select(dyear, UNIQIDNEW, trav_wt, travday) |>
  unique() |>
  summarise(N_ind = sum(trav_wt, na.rm = T),
            .by = c(dyear, travday))

N_bar_daily_BL_employed = purpose_trips_bike_BL_employed |>
  left_join(total_respondents_bike_BL,
            by = join_by(dyear, travday)) |>
  mutate(N_bar = N_trips / N_ind) |>
  summarise(across(N_bar, mean, na.rm = T), .by = c(NPT_purpose, travday)) |>
  arrange(NPT_purpose, travday)

N_bar_daily_BL_employed |>
  pivot_wider(names_from = NPT_purpose,
              values_from = N_bar,
              values_fill = 0) |>
  arrange(travday)

```

```{r}
AADT_factors_bike_BL_employed <- N_bar_daily_BL_employed |>
  mutate(d.weight = case_when(travday < 6 ~ 50,
                              travday == 6 ~ 52,
                              travday == 7 ~ 63)) |>
  summarise(AADT_bike = weighted.mean(N_bar, w = d.weight),
            .by = NPT_purpose)

AADT_factors_bike_BL_employed |>
  mutate(weekly_trips = AADT_bike*7)
```

#### All modes commute

```{r}

Commute_trips_employed = data.stage |>
  filter(between(randecon, 1, 3) | randecon == 9) |>
  left_join(NPT_purposes_equiv, by = "purpose_new") |>
  filter(NPT_purpose == "Commute") |>
  summarise(
    N_trips = n(),
    .by = c(dyear,
            travday,
            UNIQIDNEW,
            NPT_purpose, trav_wt)
  ) |>
  summarise(
    N_trips = sum(N_trips * trav_wt, na.rm = T),
    .by = c(dyear, NPT_purpose, travday)
  )

total_respondents_all = data.stage |>
  filter(between(randecon, 1, 3) | randecon == 9) |>
  select(dyear, UNIQIDNEW, trav_wt, travday) |>
  unique() |>
  summarise(N_ind = sum(trav_wt, na.rm = T),
            .by = c(dyear, travday))

N_bar_daily_employed = Commute_trips_employed |>
  left_join(total_respondents_all,
            by = join_by(dyear, travday)) |>
  mutate(N_bar = N_trips / N_ind) |>
  summarise(across(N_bar, mean, na.rm = T),
            .by = c(NPT_purpose, travday)) |>
  arrange(NPT_purpose, travday)

N_bar_daily_employed |>
  pivot_wider(names_from = NPT_purpose,
              values_from = N_bar,
              values_fill = 0) |>
  arrange(travday)
```

```{r}
AADT_factors_employed <- N_bar_daily_employed |>
  mutate(d.weight = case_when(travday < 6 ~ 50,
                              travday == 6 ~ 52,
                              travday == 7 ~ 63)) |>
  summarise(AADT_all = weighted.mean(N_bar, w = d.weight),
            .by = NPT_purpose)

AADT_factors_employed |>
  mutate(weekly_trips = AADT_all*7)
```

### Preparation of output file

This prepares the output file to be used in the main NPT project

```{r}
AADT_output <- bind_rows(AADT_factors_employed,
          AADT_factors_all |>
            filter(NPT_purpose!="Commute")) |> 
  left_join(bind_rows(AADT_factors_bike_BL_employed,
          AADT_factors_bike_BL |>
            filter(NPT_purpose!="Commute"))) |> 
  mutate(across(starts_with("AADT"),list(total = \(x) x*7))) |> 
  rename_with(.fn = ~str_replace(.x,"^AADT","Weekly"),.cols = ends_with("total"))

write_csv(AADT_output,"../npt/data-raw/AADT_factors.csv")

AADT_output
```

Committing the changes

```{r}
library(git2r)
repo <- repository("../npt/")

if(length(status(repo)[["unstaged"]])>0) {
  PAT <- cred_token()
  add(repo, path = "data-raw/AADT_factors.csv")
  commit(repo, "Update AADT factors")
  push(repo, credentials = PAT)
}
```

The total trips per day and week are summarised with the following code

```{r}
AADT_output |> 
  summarise(across(where(is.numeric),sum))
```

## References
